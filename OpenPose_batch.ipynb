{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c5a5fdc-dff5-4ba2-b502-64f231585551",
   "metadata": {},
   "source": [
    "<h1> Batch Video Tracking Using OpenPose </h1>\n",
    "    \n",
    "<img src=\"./images/envision_banner.png\" alt=\"isolated\" width=\"300\"/>\n",
    "\n",
    "<h3> James Trujillo ( james.trujillo@donders.ru.nl )<br>Wim Pouw ( wim.pouw@donders.ru.nl )<br>\n",
    "    updated: 29-08-2023 </h3>\n",
    "    \n",
    "\n",
    "<h3> Info documents </h3>\n",
    "This module demonstrates provides a simply way to batch process videos using OpenPose. \n",
    " For more information on OpenPose, its benchmarking, etc, please see:<br>\n",
    "    <i>Z. Cao, G. Hidalgo, T. Simon, S. -E. Wei and Y. Sheikh, \"OpenPose: Realtime Multi-Person 2D Pose Estimation Using Part Affinity Fields,\" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 43, no. 1, pp. 172-186, 1 Jan. 2021, doi: 10.1109/TPAMI.2019.2929257. <br>\n",
    "    Simon, T., Joo, H., Matthews, I., & Sheikh, Y. (2017). Hand keypoint detection in single images using multiview bootstrapping. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition (pp. 1145-1153). <br>\n",
    "    Cao, Z., Simon, T., Wei, S. E., & Sheikh, Y. (2017). Realtime multi-person 2d pose estimation using part affinity fields. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 7291-7299).</i>\n",
    "   \n",
    "<br><br>\n",
    "\n",
    "\n",
    "\n",
    "* Module citation: \n",
    "Trujillo, J.P. & Pouw, W.T.J.L.  (2023-08-29). <i> Batch Video Tracking Using OpenPose </i> \\[day you visited the site]. Retrieved from: https://github.com/WimPouw/envisionBOX_modulesWP/tree/main/OpenPose_batch.html\n",
    "<br>\n",
    "\n",
    "* Location of Repository:\n",
    "https://github.com/jptrujillo/OpenPose_loop_module \n",
    "<br>\n",
    "\n",
    "<h3>Introduction</h3>\n",
    "OpenPose provides a powerful form of video based motion tracking, and is freely available. OpenPose provides some advantages over other similar methods in that it can track more than one person at a time (many people, in fact!), and provides both body and hand tracking estimates. The simplest way to utilize OpenPose is to run the demo.exe file provided by the OpenPose developers. While this method is quite easy while still providing some flexibility in implementation, it is limited in that it only processes one video at a time. This module therefore provides a bash script that takes all videos in a given directory and passes them each to the demo.exe function, saving the coordinate data (i.e., x and y coordinates for each tracked keypoint) as well as a video file with the tracked points overlaid on the original video. This video output can be used to easily check or confirm tracking quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f49cadb-2a8c-42a6-b03a-32bb618a0a40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h3> Prerequisites and Set-Up:</h3>\n",
    "Before being able to run this OpenPose batch script, you will need to install: <br>\n",
    "- Git Bash (or a similar bash-capable application) https://gitforwindows.org/ <br>\n",
    "- OpenPose https://github.com/CMU-Perceptual-Computing-Lab/openpose/releases <br>\n",
    "- Note that if you want to use the cpu-only version, you need to download the cpu release, rather than the gpu release\n",
    "<br><br>\n",
    "-- After downloading and unzipping the OpenPose files, ensure that the unzipped folder, and its contents, is in the same directory as the OpenPose batch .sh file. The directory with OpenPose_loop.sh should also have a <i>bin</i>, amongst others (i.e., bin should not be within another folder) <br>\n",
    "-- note that this repository contains a <i>models</i> folder. Don't replace this with the models folder from the OpenPose download (this is due to issues with downloading the model files using OpenPose's batch file)<br>\n",
    "- Create a new directory in your repo folder called <i>output</i>. This folder is expected by the script.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992602a2-beed-4ae9-b9df-1201ca295f64",
   "metadata": {},
   "source": [
    "<h3> OpenPose</h3>\n",
    "OpenPose using pre-trained models to detect individuals and their body parts in images, and thus also in videos. The pre-trained models allow OpenPose to detect different body parts, referred to as <i>keypoints</i> in each image. By utiling \"Part Affinity Fields\", the models are also able to connect each keypoint to a particular individual, which allows tracking of multiple individuals in a single image. Note, however, that when two people cross one another, their IDs may be switched! Therefore, multi-person tracking should be used with care when tracking needs to be linked back to a particular individual. <br>\n",
    "OpenPose provides 25 keypoints for the body (shown below), 21 keypoints per hand, and 70 keypoints for the face. \n",
    "<img src=\"./images/keypoints.png\" alt=\"isolated\" width=\"300\"/>\n",
    "For each keypoint, OpenPose returns x and y values, signifying the position (in pixels) of the keypoint on the image, as well as a tracking confidence score (0-1). Tracking confidence values provide a handy way to clean the data, ensuring only datapoints where the coordinates are detected with a high degree of confidence are actually being used. Additionally, each .json file returned by OpenPose gives the person ID, which can be useful when tracking multiple people in a single video. Note also that 3D coordinate estimation is also possible using OpenPose when using multiple synchronized cameras. However, we will not cover 3D tracking in this module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9530dc2-3d58-4eef-8049-5085ab76afdd",
   "metadata": {},
   "source": [
    "<h3> Script Overview </h3>\n",
    "The file is actually being run in the next section, <i>Processing Videos</i>. There, you can see line-by-line what code has been run. This is given as an output to the actual command that we run, which is to run a .sh file. The output in this .html notebook provides a useful overview of the script, as we go over what the file is actually doing.<br>\n",
    "The file assumes a <i>videos_to_analyze</i> folder, with .avi video files. Note that this extension can be changed, or even dropped so that all files in the folder are processed. If you remove the extension filter, make sure you only have video files that you want processed in this folder! \n",
    "<br>\n",
    "After getting a list of all files, the script strips any whitespaces out of the filenames, and renames the files. This is because OpenPose does not allow spaces in filenames, and will otherwise fail to run.\n",
    "<br>\n",
    "Finally, the script passes each file to the <i>bin/OpenPoseDemo.exe</i> command. The flags specify that we want it to output a video of the tracked data, we want .json output for the actual tracking data, and we want to specify the resolution for tracking. The lower resolution is specified here simply to ensure that processing does not take too long. You can drop this flag in order to have higher quality tracking at the cost of longer (and heavier) computation. Similarly, you can add flags for hand and face tracking, using <i>--hand</i> and <i>--face</i> accordingly. Note that adding hands and face will require longer computation time, and depending on your set-up, the computer may not be able to handle this. In this case, you will get an <i>out of memory</i> error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9dc8da-a4a5-459f-af11-c932597ff222",
   "metadata": {},
   "source": [
    "<h3>Processing Videos</h3>\n",
    "To run the bash script, we use the code block below. Note that you can easily run this script outside of notebook. Just open a Bash shell in the directory of the script (in this case, ./OpenPose_batch/), and run the script directly: <i> sh OpenPose_loop.sh</i><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42eeb451-0aff-4331-8b02-4565ad2a4feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#this will go through all files with a .avi extension in the DIR path, renaming them to remove spaces, and then running the motion tracking\n",
      "#The code is currently set to do body and hand tracking, saving keypoints (joint positions) as well as the tracked video.\n",
      "\n",
      "DIR=videos_to_analyze/analyze_folder/\n",
      "for file in \"$DIR\"*.avi\n",
      "do\n",
      "\tfile_new=$(sed 's/ /_/g' <<< \"$file\") #rename the file so there are no spaces, otherwise it won't run\n",
      "\techo $file\n",
      "\techo $file_new\n",
      "\tmv \"$file\" \"$file_new\"\n",
      "\tfilename=\"${file_new##*/}\" #strip the path, so we also just have the filename\n",
      "\n",
      "\t#set output folder and filenames\n",
      "\toutput_json_folder=\"output/${filename}/\"\n",
      "\toutput_video_filename=\"${output_json_folder}video_track.avi\"\n",
      "\techo $output_video_filename\n",
      "\tmkdir $output_json_folder #make the output folder\n",
      "\n",
      "\t#run the analysis\n",
      "\tbin/OpenPoseDemo.exe --video $file_new  --write_json $output_json_folder --write_video $output_video_filename --net_resolution \"320x176\" \n",
      "donevideos_to_analyze/analyze_folder/short_vid.avi\n",
      "videos_to_analyze/analyze_folder/short_vid.avi\n",
      "output/short_vid.avi/video_track.avi\n",
      "Starting OpenPose demo...\n",
      "Configuring OpenPose...\n",
      "Starting thread(s)...\n",
      "Auto-detecting all available GPUs... Detected 1 GPU(s), using 1 of them starting at GPU 0.\n",
      "OpenPose demo successfully finished. Total time: 24.856024 seconds.\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cat OpenPose_loop.sh \n",
    "./OpenPose_loop.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90457457-fd76-4d1b-9f9a-0340f02f8ee3",
   "metadata": {},
   "source": [
    "<h3>Batching Using Python's Subprocess</h3>\n",
    "While the above example uses bash, we can also do the same using Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be10cead-8713-4627-9684-a44494c30a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short_vid.avi\n",
      "sending to command prompt:   D:\\data\\AutumnSchool2023\\OpenPose/bin/OpenPoseDemo.exe --video videos_to_analyze/analyze_folder/short_vid.avi --write_json output/short_vid --write_video output/short_vid/short_vid_video_track.avi --net_resolution  \"320x176\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "#  openpose demo.exe location\n",
    "working_dir = os.getcwd()\n",
    "openpose_demo_loc = working_dir + '/bin/OpenPoseDemo.exe' \n",
    "\n",
    "# get files to process\n",
    "file_dir = \"videos_to_analyze/analyze_folder/\"\n",
    "file_list = os.listdir(file_dir)\n",
    "\n",
    "def runcommand(command):\n",
    "        # Run the command using subprocess for OPENPOSE TRACKING\n",
    "    try:\n",
    "        subprocess.run(command, shell=True, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command execution failed with error code {e.returncode}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"The OpenPoseDemo.exe executable was not found.\")\n",
    "\n",
    "\n",
    "for filename in file_list:\n",
    "    print(filename)\n",
    "    filename.replace(\" \", \"_\")\n",
    "    #identify all mp4 files in folder\n",
    "    \n",
    "    # create output directory\n",
    "    output_dir = \"output/\" + filename[:-4]\n",
    "    if not os.path.exists(outputdir):\n",
    "        os.makedirs(outputdir)\n",
    "\n",
    "    # create the command \n",
    "    openposelocation = ' ' + openpose_demo_loc + ' '\n",
    "    video = '--video ' + file_dir + filename + ' '\n",
    "    todo = '--write_json ' + output_dir + ' '\n",
    "    videoadd = '--write_video '\n",
    "    videopath =  output_dir + '/' + filename[:-4] + '_video_track.avi '\n",
    "    res_val = '\"320x176\"'\n",
    "    resolution =  f\"--net_resolution  {res_val}\"\n",
    "    #command = [openposelocation, video, todo, videoadd, videopath, '--net_resolution \"320x126\"'] \n",
    "    command = r' '+openposelocation+video+todo+videoadd+videopath+resolution\n",
    "    print('sending to command prompt: ' + command)\n",
    "    runcommand(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eac327-58de-44bc-aeec-9cac9ad4b010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
